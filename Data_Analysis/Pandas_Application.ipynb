{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "<h4>Read the cvs file, and define first column as the index.</h4>\n",
    "\n",
    " - By default, index_col = None, which gives us __range(n)__ as the index\n",
    " - You can theoretically assign any column as the row index by index_col = 'column lable' or integer index of that column. In this example, it makes sense to assign the first column (column 0, \"company\") as the row index.\n",
    " - Check out the difference by changing __index_col = None__ \n",
    "\n",
    "\n",
    "f500 = pd.read_csv('f500.csv', index_col=0) ## or index_col = 'company'\n",
    "\n",
    "f500.index.name = None    # The index column has no name. What will it be if this line is commented out?\n",
    "\n",
    "f500.head()\n",
    "\n",
    "<h3>Instead of loading the entire dataset at once (the file may be too big), you can load first few rows first to take a quick look.</h3>\n",
    "\n",
    "# Load the first 10 rows of the dataset by setting the \"nrows\" parameter\n",
    "\n",
    "f500_short = pd.read_csv('f500.csv', index_col = 0, nrows = 10)\n",
    "f500_short.index.name = None\n",
    "\n",
    "f500_short\n",
    "\n",
    "<h3>You can also only load some columns that you want to analyze.</h3>\n",
    "\n",
    "# Load three columns by setting up \"usecols\" parameter\n",
    "f500_short =  pd.read_csv('f500.csv', index_col = 0, nrows = 10, usecols=['company','revenues','profits'])\n",
    "f500_short.index.name = None\n",
    "\n",
    "f500_short\n",
    "\n",
    "<h3>Basic DataFrame Exploration</h3>\n",
    "    \n",
    "<h3>df.info( ): details of the DataFrame - shape, row index, column labels, dtypes</h3>\n",
    "\n",
    "f500.info()        \n",
    "\n",
    "f500.shape           # 500 rows, 16 columns\n",
    "\n",
    "<h3>The company names are used as index</h3>\n",
    "\n",
    "f500.index\n",
    "\n",
    "<h3>The first row is the column labels</h3>\n",
    "\n",
    "f500.columns     \n",
    "\n",
    "<h3>Simple Data Cleaning</h3>\n",
    "<h3>We notice there are some \"Null\" values in some columns</h3>\n",
    "\n",
    "* For example, \"profit_change\" column has 436 non-null values (i.e., 64 nulls)\n",
    "* __df.isnull( )__: generating a Boolean array indicating missing values\n",
    "\n",
    "\n",
    "f500['profit_change'].isnull()\n",
    "\n",
    "f500['profit_change'].isnull().sum()    \n",
    "\n",
    "<h3>Where are those null values in \"profit_change\"?</h3>\n",
    "\n",
    "* __np.where( )__ returns the indices in a tuple\n",
    "\n",
    "np.where(f500['profit_change'].isnull())\n",
    "\n",
    "<h3> Exploring Column Data</h3>\n",
    "<h3>Selecting a single column by specifying a column label</h3>\n",
    "\n",
    "\n",
    "sector = f500['sector']   # This will extract the column data 'sector'\n",
    "\n",
    "sector = f500.loc[:,'sector']  # use DataFrame.loc attribute\n",
    "\n",
    "sector = f500.sector\n",
    "\n",
    "sector\n",
    "\n",
    "type(sector)       # Note that the column data is a pandas Series \n",
    "\n",
    "<h3>Explore pd.Series.value_counts: it return a Series containing counts of unique values.</h3>\n",
    "         \n",
    "    pd.Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)\n",
    "           * return a Series containing counts of unique values\n",
    "           * normalize: (bool) return frequency (in %) of occurrence of the unique value\n",
    "           * sort: (bool) by frequency\n",
    "           * ascending: (bool) sort in ascending order\n",
    "           * bins: (int) group values into half-open bins, only works with numeric data.\n",
    "           * dropna: (bool) drop NaN - don't count NaN\n",
    "\n",
    "\n",
    "sector_count = sector.value_counts()\n",
    "\n",
    "sector_count\n",
    "\n",
    "<h3>Question: How about we only want to capture data from 'Energy', 'Transportation' \n",
    "and 'Industrial' sectors?</h3>\n",
    "\n",
    "\n",
    "print (sector_count.index)     # Note: the sector names become the 'index' of the Series\n",
    "\n",
    "sector_3_count = sector_count[['Energy','Transportation','Industrials']]\n",
    "\n",
    "sector_3_count\n",
    "\n",
    "sector = f500['sector']    # sector is a Series \n",
    "sector_count = sector.value_counts(normalize=True)\n",
    "\n",
    "sector_count\n",
    "\n",
    "<h3>Find out the distributions for Profits by setting the 'bins' parameter.\n",
    "Let's divide the data into 10 bins</h3>\n",
    "\n",
    "\n",
    "profit = f500['profits']\n",
    "profit\n",
    "\n",
    "profit_count = profit.value_counts(sort=False, bins=20)\n",
    "profit_count\n",
    "\n",
    "<h3>Examine the DataFrame Statistics </h3>\n",
    "\n",
    "f500.describe()\n",
    "\n",
    "f500.profits.describe()\n",
    "\n",
    "<h3>We see the most profitable company made more than $45B. Which company is this?</h3>\n",
    "\n",
    "__Use pd.Series.max() & pd.Series.idxmax()__\n",
    "\n",
    "# Confirm the best profit\n",
    "f500.profits.max()\n",
    "\n",
    "f500.profits.idxmax()\n",
    "\n",
    "<h3>How about the 5 most profitable companies?</h3>\n",
    "\n",
    "__Use pd.Series.nlargest(n)__\n",
    "\n",
    "n = 5\n",
    "f500.profits.nlargest(n)\n",
    "\n",
    "<h3>A general approach for column data sorting: use pd.Series.sort_values</h3>\n",
    "\n",
    "f500.profits.sort_values(ascending=False)\n",
    "\n",
    "f500.profits.sort_values(ascending=False).head(5)\n",
    "\n",
    "<h3>Let's slice some data</h3>\n",
    "<h3>Select a list of rows and columns by labels</h3>\n",
    "\n",
    "row = [\"Walmart\", \"State Grid\", \"Sinopec Group\", 'China National Petroleum','Toyota Motor']\n",
    "col = [\"rank\", \"revenues\", \"profits\", \"country\"]\n",
    "\n",
    "f500_sel = f500.loc[row, col]\n",
    "\n",
    "f500_sel\n",
    "\n",
    "# Selecting a slice of columns by labels\n",
    "\n",
    "ceo_to_sector = f500.loc[:, \"ceo\":\"sector\"]\n",
    "ceo_to_sector\n",
    "\n",
    "### Selecting a single row by index/label\n",
    "\n",
    "\n",
    "apple = f500.loc[\"Apple\"]  # Use the df.loc() attribute\n",
    "\n",
    "#apple = f500[\"Apple\"]     # Note: This shorthand command does not work for row selection. \n",
    "\n",
    "apple\n",
    "\n",
    "### Selecting a list of rows by index/labels\n",
    "\n",
    "apple_samsung = f500.loc[[\"Apple\", \"Samsung Electronics\"]]\n",
    "\n",
    "print(type(apple_samsung))         # Note: apple_samsung is a dataframe\n",
    "\n",
    "apple_samsung.T         # A simple transpose to have a better side-by-side comparison\n",
    "\n",
    "### Question: How about extracting a slice of rows?\n",
    "\n",
    "slice_of_rows = f500[\"AT&T\":\"Ford Motor\"]       # This works for slicing the rows, but not for columns.\n",
    "                                                \n",
    "slice_of_rows = f500.loc[\"AT&T\":\"Ford Motor\"]   # This works the same.\n",
    "\n",
    "slice_of_rows.T\n",
    "\n",
    "<h3>Putting it together: get a slice of data out of some columns and rows </h3>\n",
    "<h3>       df.loc[row_sel, col_sel]: row_sel & col_sel are a list of labels  </h3>\n",
    "\n",
    "company = ['Aviva', 'HP', 'JD.com']\n",
    "ranking = ['rank', 'previous_rank']\n",
    "\n",
    "big_mover = f500.loc[company, ranking]\n",
    "\n",
    "print (type(big_mover))\n",
    "\n",
    "big_mover\n",
    "\n",
    "<h3>Q: How to add a new column to the dataframe, big_mover </h3>\n",
    "<h3>A: By simply adding a new column label with assgined new data</h3>\n",
    "\n",
    "# We want to add a column to calculate the ranking differnce\n",
    "# This is Series element-wise arithmetic \n",
    "\n",
    "big_mover['rank +/-'] = big_mover['rank'] - big_mover['previous_rank']\n",
    "\n",
    "big_mover\n",
    "\n",
    "<h3>Remove a column using df.drop( )</h3>\n",
    "\n",
    "big_mover.drop(columns=['rank +/-'], inplace=True)\n",
    "\n",
    "big_mover\n",
    "\n",
    "<h3>Another example of slicing the data</h3>\n",
    "\n",
    "col_sel = ['rank', 'sector', 'country']\n",
    "\n",
    "last_10 = f500.loc['National Grid':'AutoNation', col_sel]\n",
    "\n",
    "print (last_10)\n",
    "\n",
    "<h3> Use Series.describe method to get a glimpse into the data</h3>\n",
    "\n",
    "__For numerical Series: # of non-null values, mean, std, max, mim etc.__\n",
    "\n",
    "\n",
    "profit_change = f500['profit_change']    # It is a Series of numerical values\n",
    "\n",
    "profit_change.describe()\n",
    "\n",
    "# This is equivalent to \n",
    "# profit_change.count()\n",
    "# profit_change.mean()\n",
    "# profit_change.std()\n",
    "# profit_change.max() & min()\n",
    "\n",
    "<h3>Use Series.describe method to get a glimpse into the data</h3>\n",
    "<h3>This is an example for non-numerical Series</h3>\n",
    "\n",
    "country = f500['country']\n",
    "\n",
    "# Since \"Country\" is a non-numerical column, pandas provides the following:\n",
    "# 1. count: total number of data \n",
    "# 2. unique country names \n",
    "# 3. top: the country that appears the most times\n",
    "# 4. freq: number of companies from that country\n",
    "\n",
    "country.describe()\n",
    "\n",
    "<h3>Recall Series.value_counts can give you counts of unique values</h3>\n",
    "\n",
    "country_count = country.value_counts()   # country_count is also a pandas Series\n",
    "\n",
    "print (country_count)\n",
    "\n",
    "# Combined with Series.loc() method to access individual value\n",
    "\n",
    "print ('\\nNumber of Fortune 500 from China =', country_count.loc['China'])\n",
    "\n",
    "<h3>Sometimes the table entries may be null (i.e., no data) or NaN.</h3>\n",
    "<h3>We can use Series.isnull() or Series.notnull() to identify them in a column</h3>\n",
    "\n",
    "rev_is_null = f500[\"revenue_change\"].isnull()    # examine the \"revenue_change\" column\n",
    "\n",
    "rev_change_null = f500[rev_is_null]              # rev_is_null: a bollean array\n",
    "\n",
    "rev_change_null  #[[\"country\",\"sector\"]]\n",
    "\n",
    "<h3>In the previous_rank column, we notice some 'zeros' which indicate the companies were\n",
    "not ranked last year (new comers of Fortune 500).</h3>\n",
    "<h3>This does not make sense. Let's change them to NaN </h3>\n",
    "<h3>Q: How many new comers to join Fortune 500?</h3>\n",
    "\n",
    "rank_is_zero = f500[\"previous_rank\"] == 0    # boolean array for prev rank == 0\n",
    "\n",
    "rank_is_zero.sum()\n",
    "\n",
    "f500.loc[rank_is_zero, \"previous_rank\"] = np.nan  # replace 0 with NaN\n",
    "\n",
    "f500.loc[f500['previous_rank'].isnull(), ['rank', 'previous_rank']]\n",
    "\n",
    "### Suppose we want to find out the companies with revenue more than $100B but with negative profit (it happened!)\n",
    "### This requires a combined boolean logic \n",
    "\n",
    "\n",
    "combined = (f500[\"revenues\"] > 100000) & (f500[\"profits\"] < 0)   # companies fulfill both criteria\n",
    "\n",
    "f500.loc[combined, ['revenues','profits']]\n",
    "\n",
    "### Sorting a DataFrame: sort_values()\n",
    "\n",
    "### From earlier analysis, we know there are 51 Japanese companies on the list\n",
    "### We want to know which companies in Japan hired the most employees.\n",
    "\n",
    "# This will select all the rows where the country column equals 'Japan'\n",
    "\n",
    "japan = f500[f500[\"country\"] == \"Japan\"]\n",
    "\n",
    "japan.head()   #.employees\n",
    "\n",
    "### Use the DataFrame.sort_values() method to sort the rows on the employees column\n",
    "### The default sorting is ascending order. Use ascending=False to sort in descending order\n",
    "\n",
    "\n",
    "japan_employees = japan.sort_values(\"employees\", ascending=False)\n",
    "\n",
    "print(japan_employees[[\"country\", \"employees\"]].head())\n",
    "\n",
    "<h3>Sorting a DataFrame: sort_index()</h3>\n",
    "\n",
    "# You can also sort by row indices and column labels\n",
    "\n",
    "# Arrange the list by the alphabetical order of the company names\n",
    "\n",
    "f500_sorted = f500.sort_index()    # sort by the row index (i.e., the company names)\n",
    "\n",
    "f500_sorted[['rank','profits']]\n",
    "\n",
    "<h3>It is not that interesting to sort the columns in this example. However, you can use sort_index(axis=1) to rearrnage the columns.</h3>\n",
    "\n",
    "f500_sorted = f500.sort_index(axis=1)    # sort by the column labels\n",
    "\n",
    "f500_sorted.columns\n",
    "\n",
    "<h3>Data aggregation: adding a new column data into f500</h3>\n",
    "\n",
    "__Return on Assets (ROA) is a common business metric that  which indicates a company's ability to make profit using its assets.__\n",
    "* ROA = Profits / Assets\n",
    "\n",
    "# First, let's create a new column named ROA\n",
    "\n",
    "f500['ROA'] = f500[\"profits\"] / f500[\"assets\"]\n",
    "\n",
    "# It will be interesting to find out the company with the highest ROA in each industry sector.\n",
    "# This is a simple example of data aggregation.\n",
    "\n",
    "# Visit our old friend Dict() & for loop\n",
    "\n",
    "top_roa_by_sector = {}\n",
    "\n",
    "sector = f500['sector'].unique()   # use the unique() method to find out the unique sector names\n",
    "print (sector)\n",
    "print ('')\n",
    "\n",
    "for sec in sector:\n",
    "    is_sector = f500[\"sector\"] == sec\n",
    "    sector_companies = f500.loc[is_sector]    # This will extract all companies in the sector \n",
    "    top_company = sector_companies.sort_values(\"ROA\", ascending=False)  # sort by ROA in the sector\n",
    "    company_name = top_company.index[0]       # grab the name of the top ROA company \n",
    "    top_roa_by_sector[sec] = company_name\n",
    "    roa = f500.loc[company_name,'ROA']\n",
    "    print (f'{sec} {company_name}\\t {roa}')\n",
    "\n",
    "<h3>However, this approach is not efficient. With pandas, we can use Groupby to make this easy and elegant</h3>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
