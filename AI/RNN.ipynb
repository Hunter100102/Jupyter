{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CPE 4903 - Prediction of Time Series: RNN ##\n",
    "Predict [y(t+n)] given x(t-time_steps)...x(t), x(t) = [1 2 3 4 5 4 3 2 1 2 3 ...] sawtooth\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, SimpleRNN\n",
    "from keras.models import Model, Sequential\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "def plot_loss(history, title):\n",
    "# summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss: ' + title)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.show()\n",
    "    print('MSE val = ', history.history['val_loss'][-1])\n",
    "\n",
    "def plot_y_yhat(x_test, y_test, model, title):\n",
    "#y_pred = model.predict(X_test)\n",
    "    y_hat = model.predict(x_test)\n",
    "    Time_test = np.arange(0, len(y_hat))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(Time_test, y_hat, '-+', Time_test, y_test)\n",
    "    plt.legend(['Predicted', 'True'], loc='upper right')\n",
    "    plt.title('Y vs Yhat: ' + title)\n",
    "    results = model.evaluate(x_test, y_test)\n",
    "    print(\"test loss, test acc:\", results)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "if True: #sawtooth waveform\n",
    "    x = np.array([1, 2, 3, 4, 5, 4, 3, 2, 1, 2, 3, 4, 5, 4, 3, 2, 1, 2, 3, 4, 5, 4, 3, 2, 1, 2, 3, 4, 5, 4])\n",
    "    x = x.reshape(-1,1)\n",
    "else:\n",
    "    time = np.arange(0, 100, 0.1)\n",
    "    signal = np.sin(time) * np.sin(5*time + .25) + np.sin(.5*time + .35)\n",
    "    noise = 0*np.random.normal(scale=0.5, size=len(time))\n",
    "    data = signal + noise\n",
    "    x = data\n",
    "    x = x.reshape(-1,1)\n",
    "\n",
    "\n",
    "x.shape\n",
    "\n",
    "x.T\n",
    "\n",
    "plt.plot(x)\n",
    "\n",
    "train_size = int(len(x) * 0.7)\n",
    "test_size = len(x) - train_size\n",
    "train = x[:train_size]\n",
    "test = x[train_size:]\n",
    "\n",
    "train = train.reshape(-1,1)\n",
    "test = test.reshape(-1,1)\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# simple scaling\n",
    "#train = train/np.max(train)\n",
    "#test = test/np.max(test)\n",
    "\n",
    "print(train)\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "#train = data\n",
    "time_steps =4\n",
    "n = 1 # prediction y(t+n) ahead\n",
    "\n",
    "\n",
    "# Train sets\n",
    "m_train = len(train)\n",
    "\n",
    "# TimeseriesGenerator generates matrix X_train with shape (m_train-time_steps-n+1, time_steps)\n",
    "# y_train with shape ((m_train-time_steps-n+1, 1)\n",
    "\n",
    "target = np.roll(train,1-n) # pre shift left n-1 \n",
    "dataset = TimeseriesGenerator(train, target , length=time_steps, batch_size = m_train-time_steps-n+1)\n",
    "X_train, y_train = dataset[0]  # first sample X_train[0] = train[0..time_steps-1], y_train = [time_steps+n-1] n step ahead \n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "print('X_train and y_train shapes: ', [X_train.shape, y_train.shape])\n",
    "\n",
    "# Test sets\n",
    "m_test = len(test)\n",
    "target = np.roll(test,1-n)\n",
    "dataset = TimeseriesGenerator(test, target , length=time_steps, batch_size = m_test-time_steps-n+1)\n",
    "X_test, y_test = dataset[0]\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print('X_test and y_test shapes: ', [X_test.shape, y_test.shape])\n",
    "\n",
    "\n",
    "X_train\n",
    "\n",
    "y_train\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "y_train.shape\n",
    "\n",
    "print(y_train)\n",
    "\n",
    "x\n",
    "\n",
    "m = len(y_train)\n",
    "nx = 1 # dim of x<t>\n",
    "print('m, time_steps, n = look_ahead, nx: ', m, time_steps, n, nx)\n",
    "\n",
    "\n",
    "\n",
    "# RNN #\n",
    "hidden_neurons = 64\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=hidden_neurons, input_shape=(time_steps, nx)))\n",
    "model.add(Dense(units=200,activation='relu'))\n",
    "model.add(Dense(units=1, activation=None))\n",
    "opt=keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer=opt, metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "yhat_test = model.predict(X_test)\n",
    "\n",
    "plot_loss(history, 'RNN')\n",
    "\n",
    "plot_y_yhat(X_test, y_test, model, 'RNN')   # runs model.predict in function\n",
    "\n",
    "#train = data\n",
    "time_steps =4\n",
    "n = 2 # prediction y(t+n) ahead\n",
    "\n",
    "\n",
    "# Train sets\n",
    "m_train = len(train)\n",
    "\n",
    "# TimeseriesGenerator generates matrix X_train with shape (m_train-time_steps-n+1, time_steps)\n",
    "# y_train with shape ((m_train-time_steps-n+1, 1)\n",
    "\n",
    "target = np.roll(train,1-n) # pre shift left n-1 \n",
    "dataset = TimeseriesGenerator(train, target , length=time_steps, batch_size = m_train-time_steps-n+1)\n",
    "X_train, y_train = dataset[0]  # first sample X_train[0] = train[0..time_steps-1], y_train = [time_steps+n-1] n step ahead \n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "print('X_train and y_train shapes: ', [X_train.shape, y_train.shape])\n",
    "\n",
    "# Test sets\n",
    "m_test = len(test)\n",
    "target = np.roll(test,1-n)\n",
    "dataset = TimeseriesGenerator(test, target , length=time_steps, batch_size = m_test-time_steps-n+1)\n",
    "X_test, y_test = dataset[0]\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print('X_test and y_test shapes: ', [X_test.shape, y_test.shape])\n",
    "\n",
    "m = len(y_train)\n",
    "nx = 1 # dim of x<t>\n",
    "print('m, time_steps, n = look_ahead, nx: ', m, time_steps, n, nx)\n",
    "\n",
    "\n",
    "\n",
    "# RNN #\n",
    "hidden_neurons = 64\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=hidden_neurons, input_shape=(time_steps, nx)))\n",
    "model.add(Dense(units=200,activation='relu'))\n",
    "model.add(Dense(units=1, activation=None))\n",
    "opt=keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer=opt, metrics = ['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "plot_loss(history, 'RNN')\n",
    "\n",
    "plot_y_yhat(X_test, y_test, model, 'RNN')   # runs model.predict in function\n",
    "\n",
    "# As we may see from the two graphs when n is increased to n = 2 our predictions became more accurate. Although it appears\n",
    "# that before epoch 50 n=1 is more stable and accurate for the train vs the validations. This can be seen in the loss chart.\n",
    "# However, after 200 iterations the loss for n=2 was significantly less than that of n=1. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
